# Flujo Completo del Programa para Obtener Texto desde una Imagen

## ğŸ“Š Diagrama de Flujo General

```
IMAGEN ORIGINAL
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 1: PREPROCESAMIENTO (7 pasos)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
IMAGEN BINARIA LIMPIA
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 2: DETECCIÃ“N CRAFT                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
REGIONES DE TEXTO DETECTADAS (Bounding Boxes)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 3: RECORTE DE REGIONES            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
IMÃGENES INDIVIDUALES DE CADA REGIÃ“N
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FASE 4: RECONOCIMIENTO CRNN            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
TEXTO FINAL
```

---

## ğŸ” Flujo Detallado Paso a Paso

### **FASE 1: PREPROCESAMIENTO** (`preprocesamiento_ocr.py`)
Transforma la imagen original en una imagen binaria optimizada para detecciÃ³n de texto.

#### **Paso 1.1: ConversiÃ³n a Escala de Grises**
```
Entrada: Imagen RGB (ej. 1920x1080x3)
Proceso: rgb_a_grises(imagen)
Salida: Imagen en grises (1920x1080x1)
PropÃ³sito: Reducir dimensionalidad, simplificar procesamiento
```

**CÃ³digo:**
```python
def _convertir_grises(self, imagen: np.ndarray) -> np.ndarray:
    if len(imagen.shape) == 3:
        return rgb_a_grises(imagen)
    return imagen
```

---

#### **Paso 1.2: Limpieza de Ruido Inicial (Mediana 5x5)**
```
Entrada: Imagen en grises
Proceso: cv2.medianBlur(imagen, 5)
Salida: Imagen sin ruido sal y pimienta
PropÃ³sito: Eliminar puntos blancos/negros aleatorios
```

**CÃ³digo:**
```python
def _limpieza_ruido_inicial(self, imagen: np.ndarray) -> np.ndarray:
    return cv2.medianBlur(imagen, 5)
```

**Por quÃ© funciona:**
- El filtro de mediana reemplaza cada pÃ­xel por la mediana de sus vecinos
- Kernel 5x5 = considera 25 pÃ­xeles alrededor
- Elimina ruido impulsivo sin desenfocar tanto como un filtro gaussiano

---

#### **Paso 1.3: ReducciÃ³n de Ruido (Filtro Bilateral)**
```
Entrada: Imagen sin ruido inicial
Proceso: cv2.bilateralFilter(d=5, sigmaColor=50, sigmaSpace=50)
Salida: Imagen suavizada preservando bordes
PropÃ³sito: Reducir texturas y ruido manteniendo bordes de letras nÃ­tidos
```

**CÃ³digo:**
```python
def _reducir_ruido_bilateral(self, imagen: np.ndarray) -> np.ndarray:
    return cv2.bilateralFilter(imagen, d=5, sigmaColor=50, sigmaSpace=50)
```

**ParÃ¡metros:**
- `d=5`: DiÃ¡metro del vecindario (5 pÃ­xeles)
- `sigmaColor=50`: Rango de colores considerados similares
- `sigmaSpace=50`: Distancia espacial considerada

**Ventaja sobre Gaussiano:**
- Suaviza Ã¡reas planas (fondo) pero mantiene bordes afilados (letras)

---

#### **Paso 1.4: Mejora de Contraste (CLAHE)**
```
Entrada: Imagen suavizada
Proceso: CLAHE(clipLimit=2.5, tileGridSize=(6,6))
Salida: Imagen con contraste local mejorado
PropÃ³sito: Corregir iluminaciÃ³n irregular, resaltar texto dÃ©bil
```

**CÃ³digo:**
```python
def _mejorar_contraste(self, imagen: np.ndarray) -> np.ndarray:
    clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(6, 6))
    return clahe.apply(imagen)
```

**CLAHE = Contrast Limited Adaptive Histogram Equalization**
- **Adaptive**: Divide la imagen en tiles (6x6)
- **Histogram Equalization**: Redistribuye intensidades en cada tile
- **Contrast Limited (2.5)**: Evita amplificaciÃ³n excesiva de ruido

**Ejemplo visual:**
```
Antes CLAHE:          DespuÃ©s CLAHE:
â–‘â–‘â–‘â–‘â–“â–“â–“â–“             â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆ
â–‘â–‘â–‘â–‘â–“â–“â–“â–“     â†’       â–‘â–‘â–‘â–‘â–ˆâ–ˆâ–ˆâ–ˆ
(bajo contraste)     (alto contraste)
```

---

#### **Paso 1.5: UmbralizaciÃ³n Adaptativa (GAUSSIAN)**
```
Entrada: Imagen con contraste mejorado
Proceso: adaptiveThreshold(blockSize=13, C=3, GAUSSIAN)
Salida: Imagen BINARIA (blanco/negro puro)
PropÃ³sito: Separar texto del fondo, binarizaciÃ³n local
```

**CÃ³digo:**
```python
def _umbralizar_adaptativo(self, imagen: np.ndarray) -> np.ndarray:
    return cv2.adaptiveThreshold(
        imagen, 
        255, 
        cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
        cv2.THRESH_BINARY,
        13,  # TamaÃ±o de bloque
        3    # Constante C
    )
```

**CÃ³mo funciona:**
1. Divide imagen en bloques de 13x13 pÃ­xeles
2. Calcula umbral local usando promedio ponderado Gaussiano
3. Umbral = Media_Gaussiana - C (C=3)
4. PÃ­xel > Umbral â†’ Blanco (255), sino â†’ Negro (0)

**Ventaja sobre umbralizaciÃ³n global:**
- Se adapta a cambios de iluminaciÃ³n
- Funciona con sombras y brillos locales

---

#### **Paso 1.6: Cierre MorfolÃ³gico**
```
Entrada: Imagen binaria
Proceso: morphologyEx(MORPH_CLOSE, kernel=1x1)
Salida: Imagen con trazos conectados
PropÃ³sito: Unir partes fragmentadas de letras
```

**CÃ³digo:**
```python
def _operacion_morfologica_cierre(self, imagen: np.ndarray) -> np.ndarray:
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 1))
    return cv2.morphologyEx(imagen, cv2.MORPH_CLOSE, kernel, iterations=1)
```

**Cierre = DilataciÃ³n + ErosiÃ³n:**
1. **DilataciÃ³n**: Expande regiones blancas (letras)
2. **ErosiÃ³n**: Contrae de vuelta pero mantiene conexiones

**Ejemplo:**
```
Antes:           DespuÃ©s:
â–ˆâ–ˆ  â–ˆâ–ˆ           â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
â–ˆâ–ˆ  â–ˆâ–ˆ    â†’      â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
(desconectado)   (conectado)
```

---

#### **Paso 1.7: Limpieza Final (Mediana 5x5)**
```
Entrada: Imagen con morfologÃ­a aplicada
Proceso: cv2.medianBlur(imagen, 5)
Salida: Imagen binaria LIMPIA (lista para CRAFT)
PropÃ³sito: Eliminar artefactos finales
```

**CÃ³digo:**
```python
def _limpieza_ruido_final(self, imagen: np.ndarray) -> np.ndarray:
    return cv2.medianBlur(imagen, 5)
```

**Por quÃ© otra vez mediana:**
- Las operaciones anteriores pueden generar nuevos artefactos
- Limpieza agresiva final garantiza imagen perfecta para detecciÃ³n

---

### **FASE 2: DETECCIÃ“N DE TEXTO CON CRAFT** (`pipeline_detallado_ocr.py`)
Localiza dÃ³nde estÃ¡ el texto en la imagen usando Deep Learning.

```
Entrada: Imagen binaria limpia
Proceso: 
  1. reader.readtext(imagen, paragraph=False, min_size=10, 
                     text_threshold=0.7, low_text=0.4)
  2. EasyOCR ejecuta CRAFT (red neuronal convolucional)
  3. CRAFT genera un "mapa de calor" de probabilidades de texto
  4. Se extraen bounding boxes de regiones con alta probabilidad
```

#### **Arquitectura CRAFT:**
```
Imagen â†’ CNN â†’ Mapa de Regiones â†’ Mapa de Afinidad â†’ Bounding Boxes
         â†“                          â†“
    [Detecta caracteres]    [Detecta conexiones]
```

#### **ParÃ¡metros optimizados:**
```python
resultados = self.reader.readtext(
    imagen_binaria, 
    detail=1,
    paragraph=False,      # Detectar lÃ­neas individuales, no pÃ¡rrafos
    min_size=10,          # TamaÃ±o mÃ­nimo de texto (px)
    text_threshold=0.7,   # Umbral de confianza para detecciÃ³n (70%)
    low_text=0.4          # Umbral para regiones de texto dÃ©bil
)
```

#### **Filtrado post-detecciÃ³n:**
```python
# Eliminar regiones muy pequeÃ±as (ruido)
if area < 50:
    continue

# Eliminar regiones muy grandes (falsos positivos)
if area > area_imagen * 0.8:
    continue

# Filtrar proporciones anormales
aspect_ratio = ancho / alto
if aspect_ratio < 0.1 or aspect_ratio > 50:
    continue

# Agregar padding de 3px
x_min = max(0, x_min - 3)
y_min = max(0, y_min - 3)
x_max = min(w, x_max + 3)
y_max = min(h, y_max + 3)
```

#### **Ordenamiento de regiones:**
```python
def _ordenar_regiones(self, regiones: List[Dict]) -> List[Dict]:
    def clave_ordenamiento(region):
        centro_x, centro_y = region['centro']
        # Agrupar por lÃ­neas con tolerancia de 20 pÃ­xeles
        linea = centro_y // 20
        return (linea, centro_x)
    
    return sorted(regiones, key=clave_ordenamiento)
```

**Resultado:**
- Regiones ordenadas de arribaâ†’abajo, izquierdaâ†’derecha
- Orden natural de lectura

#### **Salida de FASE 2:**
```python
regiones = [
    {
        'id': 1,
        'bbox': (100, 50, 300, 80),
        'area': 6000,
        'centro': (200, 65),
        'confianza_deteccion': 0.95
    },
    {
        'id': 2,
        'bbox': (120, 100, 280, 130),
        'area': 4800,
        'centro': (200, 115),
        'confianza_deteccion': 0.88
    }
]
```

---

### **FASE 3: RECORTE DE REGIONES** (`pipeline_detallado_ocr.py`)
Extrae cada regiÃ³n detectada como una imagen independiente.

```python
def paso_3_recortar_regiones(self, imagen_original, regiones):
    regiones_recortadas = []
    
    for region in regiones:
        x_min, y_min, x_max, y_max = region['bbox']
        
        # Recortar regiÃ³n
        img_recortada = imagen_original[y_min:y_max, x_min:x_max]
        
        region_info = {
            'id': region['id'],
            'bbox': region['bbox'],
            'imagen': img_recortada,
            'tamaÃ±o': (x_max - x_min, y_max - y_min)
        }
        regiones_recortadas.append(region_info)
    
    return regiones_recortadas
```

**VisualizaciÃ³n:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Imagen Original                      â”‚
â”‚                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚  â”‚ RegiÃ³n 1â”‚ â† Recortada              â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â”‚                                       â”‚
â”‚       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                     â”‚
â”‚       â”‚ RegiÃ³n 2â”‚ â† Recortada         â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Resultado:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ "HELLO"  â”‚  â”‚ "WORLD"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### **FASE 4: RECONOCIMIENTO DE TEXTO CON CRNN** (`pipeline_detallado_ocr.py`)
Procesa cada regiÃ³n individualmente para extraer los caracteres.

#### **Arquitectura CRNN:**
```
Imagen â†’ CNN â†’ Mapa de caracterÃ­sticas â†’ RNN â†’ CTC â†’ Texto
         â†“                                â†“      â†“
    [CaracterÃ­sticas]              [Secuencia] [DecodificaciÃ³n]
```

#### **CÃ³digo:**
```python
def paso_4_reconocimiento_crnn(self, regiones_recortadas):
    texto_completo = []
    detalles = []
    
    for region in regiones_recortadas:
        # Reconocer texto en la regiÃ³n recortada
        resultado = self.reader.readtext(region['imagen'], detail=1)
        
        if resultado:
            # Tomar el resultado con mayor confianza
            mejor_resultado = max(resultado, key=lambda x: x[2])
            bbox, texto, confianza = mejor_resultado
            
            detalle = {
                'id': region['id'],
                'texto': texto,
                'confianza': confianza * 100,
                'bbox_original': region['bbox'],
                'tamaÃ±o': region['tamaÃ±o']
            }
            detalles.append(detalle)
            texto_completo.append(texto)
    
    texto_final = ' '.join(texto_completo)
    return texto_final, detalles
```

#### **Componentes de CRNN:**

**1. CNN (Convolutional Neural Network):**
```
Entrada: Imagen 32x100 (normalizada)
â†“
Conv2D(64) + ReLU + MaxPool
â†“
Conv2D(128) + ReLU + MaxPool
â†“
Conv2D(256) + ReLU + MaxPool
â†“
Salida: Mapa de caracterÃ­sticas 1x25x512
```
- Extrae formas, bordes, curvas de caracteres
- Genera representaciÃ³n visual abstracta

**2. RNN (Recurrent Neural Network):**
```
Mapa de caracterÃ­sticas â†’ LSTM (256) â†’ LSTM (256) â†’ Secuencia
```
- Procesa caracterÃ­sticas de izquierda a derecha
- LSTM mantiene contexto (letra anterior influye en siguiente)
- Entiende palabras completas, no solo letras aisladas

**3. CTC (Connectionist Temporal Classification):**
```
Secuencia RNN: [H,H,E,E,L,L,L,O,O]
       â†“ (Elimina duplicados y blanks)
Texto final: "HELLO"
```
- Alinea salida variable con texto final
- No requiere segmentaciÃ³n previa
- Maneja longitudes variables

#### **Salida de FASE 4:**
```python
detalles = [
    {
        'id': 1,
        'texto': 'HELLO',
        'confianza': 94.2,
        'bbox_original': (100, 50, 300, 80),
        'tamaÃ±o': (200, 30)
    },
    {
        'id': 2,
        'texto': 'WORLD',
        'confianza': 91.8,
        'bbox_original': (120, 100, 280, 130),
        'tamaÃ±o': (160, 30)
    }
]

texto_final = "HELLO WORLD"
```

---

## ğŸ¯ Resumen del Flujo Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ IMAGEN RGB ORIGINAL                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 1: PREPROCESAMIENTO (7 pasos)                â”‚
â”‚ â€¢ Grises                                           â”‚
â”‚ â€¢ Mediana 5x5 (inicial)                            â”‚
â”‚ â€¢ Bilateral (d=5)                                  â”‚
â”‚ â€¢ CLAHE (clip=2.5)                                 â”‚
â”‚ â€¢ UmbralizaciÃ³n Gaussiana (block=13, C=3)          â”‚
â”‚ â€¢ MorfologÃ­a Cierre (1x1)                          â”‚
â”‚ â€¢ Mediana 5x5 (final)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ IMAGEN BINARIA LIMPIA                              â”‚
â”‚ (Texto blanco sobre fondo negro)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 2: DETECCIÃ“N CRAFT                            â”‚
â”‚ â€¢ Red neuronal detecta regiones de texto           â”‚
â”‚ â€¢ Filtrado de falsos positivos                     â”‚
â”‚ â€¢ Ordenamiento por posiciÃ³n                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BOUNDING BOXES                                     â”‚
â”‚ [(x1,y1,x2,y2), conf] ordenados                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 3: RECORTE                                    â”‚
â”‚ â€¢ ExtracciÃ³n de mini-imÃ¡genes                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ REGIONES INDIVIDUALES                              â”‚
â”‚ [img1, img2, img3, ...]                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FASE 4: RECONOCIMIENTO CRNN                        â”‚
â”‚ â€¢ CNN: Extrae caracterÃ­sticas visuales             â”‚
â”‚ â€¢ RNN: Procesa secuencia con contexto              â”‚
â”‚ â€¢ CTC: Decodifica a texto final                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TEXTO FINAL + CONFIANZA                            â”‚
â”‚ "HELLO WORLD" (93.5%)                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## â±ï¸ Tiempo Estimado por Fase

| Fase | Tiempo | Nota |
|------|--------|------|
| **Preprocesamiento** | 0.5-2 seg | Depende de resoluciÃ³n (1920x1080 ~1s) |
| **DetecciÃ³n CRAFT** | 2-5 seg | Primera vez carga modelo (~3s extra) |
| **Recorte** | 0.01 seg | OperaciÃ³n trivial |
| **Reconocimiento CRNN** | 0.5-1 seg/regiÃ³n | Para 5 regiones ~3 seg |
| **TOTAL** | **5-10 seg** | Imagen tÃ­pica 1080p con 3-5 regiones |

---

## ğŸ“Š MÃ©tricas de Calidad por Fase

### Fase 1 - Preprocesamiento:
- âœ… **Entrada:** Imagen ruidosa con iluminaciÃ³n irregular
- âœ… **Salida:** Imagen binaria limpia con SNR mejorado >15dB

### Fase 2 - DetecciÃ³n CRAFT:
- âœ… **PrecisiÃ³n:** ~95% en textos claros
- âœ… **Recall:** ~90% (detecta 9 de cada 10 regiones reales)
- âŒ **Fallos:** Texto muy pequeÃ±o (<10px) o rotado >45Â°

### Fase 4 - Reconocimiento CRNN:
- âœ… **Exactitud:** 85-95% en inglÃ©s
- âœ… **Confianza promedio:** 90-95%
- âŒ **Confusiones comunes:** 0/O, 1/I/l, 5/S

---

## ğŸ”§ Archivos del Proyecto

```
Proyecto/
â”œâ”€â”€ preprocesamiento_ocr.py       # FASE 1: Pipeline de 7 pasos
â”œâ”€â”€ pipeline_detallado_ocr.py     # FASES 2, 3, 4: DetecciÃ³n y reconocimiento
â”œâ”€â”€ interfaz_pipeline_detallado.py # GUI para visualizaciÃ³n
â””â”€â”€ Main_Pipeline_Detallado.py    # Punto de entrada
```

---

## ğŸš€ CÃ³mo Ejecutar

```bash
# Ejecutar interfaz grÃ¡fica
python Proyecto/Main_Pipeline_Detallado.py

# O con el entorno virtual
C:/Users/uriel/Documents/ImageAnalysis/.venv/Scripts/python.exe Proyecto/Main_Pipeline_Detallado.py
```

**Interfaz permite:**
- â¬…ï¸â¡ï¸ Navegar entre los 4 pasos principales
- â—€ï¸â–¶ï¸ Ver cada subpaso del preprocesamiento
- ğŸ‘ï¸ Visualizar imÃ¡genes intermedias
- ğŸ“Š Ver mÃ©tricas de confianza por regiÃ³n
